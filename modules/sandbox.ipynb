{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkD57Ur6E2l2",
        "outputId": "0cbc6be5-b520-45ef-f45d-d9efe2ea5b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Apple Metal (MPS) backend: mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import models\n",
        "from torchvision.models import *\n",
        "from plotly import express as px\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import random\n",
        "import multiprocessing\n",
        "\n",
        "from modules.dataset import IntelImageClassificationDataset\n",
        "from modules.utility import NotebookPlotter, InferenceSession, Evaluator, ISO_time, apply_pruning\n",
        "from modules.trainer import Trainer\n",
        "from modules.optuna_monashara import run_optuna\n",
        "from modules.BufferDataset import ShuffleBufferDataset\n",
        "\n",
        "torch.manual_seed(1)\n",
        "if torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "    print(\"Using Apple Metal (MPS) backend:\", DEVICE)\n",
        "elif torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    print(\"Using CUDA GPU:\", DEVICE)\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"Using CPU:\", DEVICE)\n",
        "\n",
        "def set_seed(seed=1):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True  # for reproducibility\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbHgev5PE2l3"
      },
      "source": [
        "https://www.kaggle.com/datasets/puneet6060/intel-image-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "3go5RaM8E2l3"
      },
      "outputs": [],
      "source": [
        "# labels, values = zip(*Counter([item[1] for item in dataset.train_dataset]).items())\n",
        "# fig = px.bar(x=labels, y=values, labels={'x': 'Categories', 'y': 'Counts'}, title='Distribution of Classes')\n",
        "# fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjZypu8jE2l3"
      },
      "source": [
        "| n | label |\n",
        "| --- | --- |\n",
        "| 0 | buildings |\n",
        "| 1 | forest |\n",
        "| 2 | glacier |\n",
        "| 3 | mountain |\n",
        "| 4 | sea |\n",
        "| 5 | street |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EJgLtsTE2l4",
        "outputId": "0cf0b3eb-2066-4448-cbc1-ed73f35e5424"
      },
      "source": [
        "NotebookPlotter.plot_dataset_item_interactive(dataset.train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zDPzrOPHMyG"
      },
      "outputs": [],
      "source": [
        "choice = 1 # 1,2,3\n",
        "freezeLayer = True\n",
        "pretrained_Weights = True\n",
        "prune_model = True\n",
        "OPTUNA_MO = False\n",
        "Multi_B = True\n",
        "\n",
        "if choice != 5:\n",
        "    dataset = IntelImageClassificationDataset(resize=(150,150))\n",
        "else:\n",
        "    dataset = IntelImageClassificationDataset(resize=(384,384))\n",
        "\n",
        "# 80% train, 20% validation for training Optuna\n",
        "train_size = int(0.8 * len(dataset.train_dataset))\n",
        "val_size = len(dataset.train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(dataset.train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(1))\n",
        "\n",
        "def build_model():\n",
        "\n",
        "  # SqueezeNet 1.1\n",
        "  if choice == 1:\n",
        "      if(pretrained_Weights):\n",
        "        model = models.squeezenet1_1(weights=SqueezeNet1_1_Weights.DEFAULT)\n",
        "      else:\n",
        "        model = models.squeezenet1_1()\n",
        "\n",
        "      num_features = model.classifier[1].in_channels\n",
        "      kernel_size = model.classifier[1].kernel_size\n",
        "      if(freezeLayer):\n",
        "          for param in model.parameters():\n",
        "              param.requires_grad = False\n",
        "      model.classifier[1] = nn.Conv2d(num_features, 6, kernel_size)\n",
        "\n",
        "  # MobileNetV3 Small\n",
        "  elif choice == 2:\n",
        "      if(pretrained_Weights):\n",
        "        model = models.mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT)\n",
        "      else:\n",
        "        model = models.mobilenet_v3_small()\n",
        "      num_features = model.classifier[3].in_features\n",
        "      if(freezeLayer):\n",
        "          for param in model.parameters():\n",
        "              param.requires_grad = False\n",
        "      model.classifier[3] = nn.Linear(num_features, 6)\n",
        "\n",
        "  if prune_model:\n",
        "    model = apply_pruning(model, amount=0.3)\n",
        "\n",
        "  return model\n",
        "\n",
        "if OPTUNA_MO:\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    best_params, best_model_state, study = run_optuna(\n",
        "        model=model,\n",
        "        train_subset=train_subset,\n",
        "        val_subset=val_subset,\n",
        "        TrainerClass=Trainer,\n",
        "        n_trials=12,\n",
        "        seed=1\n",
        "    )\n",
        "\n",
        "    print(\"▶ Per-epoch validation accuracy (best trial):\")\n",
        "    best_trial = study.best_trial\n",
        "    for epoch, acc in sorted(best_trial.intermediate_values.items()):\n",
        "        print(f\"   Epoch {epoch:2d}: {acc * 100:.2f}%\")\n",
        "\n",
        "    print(f\"\\n▶ Best hyperparameters: {best_params}\")\n",
        "    print(f\"▶ Best overall accuracy: {study.best_value * 100:.2f}%\")\n",
        "\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    dataloader = DataLoader(batch_size=best_params[\"BS_SUGGEST\"], shuffle=True)\n",
        "    dataloader = DataLoader(dataset.train_dataset, batch_size=best_params[\"BS_SUGGEST\"], shuffle=True)\n",
        "    trainer = Trainer(model=model,lr=best_params[\"LR_SUGGEST\"],device=DEVICE)\n",
        "    epochs = best_params[\"EPOCHS\"]\n",
        "\n",
        "    ''' BS_SUGGEST': 32, 'LR_SUGGEST': 8.841926348917726e-05, 'EPOCHS': 25 suggested from the OPTUNA\n",
        "        and achieve the accuracy of 86.7 % on Testdata.'''\n",
        "\n",
        "else:\n",
        "    model = build_model()\n",
        "    dataloader = DataLoader(dataset.train_dataset, batch_size=32, shuffle=True)\n",
        "    trainer = Trainer(model=model, lr=8.841926348917726e-05, device=DEVICE)\n",
        "    epochs = 25\n",
        "\n",
        "if Multi_B:\n",
        "    workers = max(1, multiprocessing.cpu_count() // 2)\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset=dataloader.dataset,\n",
        "        batch_size=dataloader.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=workers,\n",
        "        pin_memory=True,\n",
        "        persistent_workers=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "XW3sIV9KE2l4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52fbcc956fa342538984b08490f93a9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
          ]
        }
      ],
      "source": [
        "# model.load_state_dict(torch.load(f\"checkpoints/.pt\"))\n",
        "trainer.train(dataloader, epochs=epochs, silent=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VESPNHBME2l4",
        "outputId": "d4208f97-8a38-4416-d324-a4027f61ba8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8670400381088257"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "session = InferenceSession(model)\n",
        "output = session(torch.stack(tuple(item[0] for item in dataset.test_dataset)))\n",
        "Evaluator.acc(output, torch.tensor(tuple(item[1] for item in dataset.test_dataset))).item()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
